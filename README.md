
# 5G Jamming Detection using an LSTM Autoencoder

## Overview and Purpose

This project provides a complete pipeline for detecting jamming attacks on a 5G User Equipment (UE) by analyzing radio frequency (RF) metrics from srsRAN log files. The primary goal is to build a robust model that can identify anomalous network behavior indicative of jamming, even for attack patterns it has never seen before.

The core challenge in jamming detection is that attacks can be diverse and unpredictable. A simple classifier trained on known attack types might fail when faced with a novel one. This project overcomes that challenge by using an **anomaly detection** approach.

**The key purpose is not to learn what "jamming" looks like, but to develop an expert understanding of what "normal" network operation looks like and flag any significant deviation as a potential attack.**

## How it Works: Anomaly Detection with an LSTM Autoencoder

The model is a **Long Short-Term Memory (LSTM) Autoencoder** trained in PyTorch. An autoencoder is a type of neural network trained to reconstruct its own input.

1.  **Architecture:** It consists of two parts:
    *   **Encoder:** Compresses a sequence of RF metrics (like CQI, RSRP, etc.) into a small, dense representation called the "latent space" or "bottleneck." This forces the model to learn the most essential features of the data.
    *   **Decoder:** Takes the compressed representation from the bottleneck and attempts to reconstruct the original input sequence.

2.  **Training Phase (Learning "Normal"):**
    The model is trained **exclusively on data from `no_jammer` log files.** It is never shown a single example of a jamming attack during this phase. Its only goal is to become an expert at reconstructing "normal" RF signal patterns.

3.  **Detection Phase (Finding Anomalies):**
    After training, the model is used to process all data (both normal and jammed).
    *   **When given normal data:** The model is an expert at this. It reconstructs the sequence almost perfectly, resulting in a **low reconstruction error**.
    *   **When given jammed data:** The RF patterns are erratic and unfamiliar. The model struggles to compress and reconstruct this alien data, resulting in a **high reconstruction error**.

4.  **The Threshold:**
    We calculate the reconstruction error on a validation set of normal data to determine a statistical **threshold**. Any new sequence that produces an error above this threshold is classified as an **anomaly (Jamming)**.

This approach is powerful because it can detect novel jamming attacks without ever having been trained on them.

## Project Structure

```
.
├── dataset/
│   └── Jammer/
│       ├── no_jammer_run1.log
│       ├── jammer_run1.log
│       └── ... (all your other log files)
│
├── srsran_csv_output/          <-- Generated by Step 2
│   └── ... (clean CSV files)
│
├── process_logs.py             # Script to parse srsRAN logs into CSV
├── modelnew.py                 # Script to train and evaluate the model
│
├── anomaly_autoencoder_pytorch.pth  <-- Generated by Step 3 (Trained Model)
├── anomaly_scaler_pytorch.pkl       <-- Generated by Step 3 (Data Scaler)
├── anomaly_threshold.txt            <-- Generated by Step 3 (Anomaly Threshold)
|-- threshold_config.json           Threshold data for particular distances 
|-- ae_scaler.pth                   scaler for autoencoder
|-- cls_scaler.pth                  scaler for classifier
|-- scaler_divergence.pth           scaler divergence for preprocessing
└── README.md                   # This file
```

## Setup and Installation

1.  Ensure you have Python 3.8+ installed.

2.  It is highly recommended to use a virtual environment to keep dependencies clean.
    ```bash
    python3 -m venv venv
    source venv/bin/activate
    ```

3.  Install the required Python libraries. For GPU acceleration with PyTorch, please visit the [official PyTorch website](https://pytorch.org/get-started/locally/) for the correct command for your system and CUDA version.

    ```bash
    # Install PyTorch (example for CPU-only)
    pip install torch torchvision torchaudio

    # Install other necessary packages
    pip install pandas scikit-learn joblib numpy matplotlib seaborn
    ```

## Model Training
Follow these steps in order to go from raw log files to a trained jamming detection model.

### Step 1: Place Your Log Files

Place all your srsRAN log files into the `dataset/Jammer/` directory. Ensure they follow the naming convention:
-   Normal operation logs must start with `no_jammer` (e.g., `no_jammer_scenario1.log`).
-   Jamming attack logs must start with `jammer` (e.g., `jammer_scenario1.log`).

### Step 2: Create the CSV Files

The raw log files need to be parsed into a clean, structured format. The `process_logs.py` script handles this. It cleans the data, handles missing values (`na`), and most importantly, generates corresponding idle data for `ue1` for every active `ue2` timestamp.

Run the script from your terminal:
```bash
python3 process_logs.py input_fileName output_fileName
```

Place the output files in `srsran_csv_output/` directory

### Step 3: Train the Anomaly Detection Model

Now that the data is prepared, you can train the LSTM Autoencoder. The `modelnew.py` script will automatically find the `no_jammer` files for training and then use all files for evaluation.

Run the training script:
```bash
python3 modelnew.py
```

This script will:
1.  Load and preprocess only the `no_jammer` data.
2.  Train the autoencoder model on this normal data.
3.  Calculate an anomaly threshold based on a validation set of normal data.
4.  Evaluate the model's performance on the entire dataset (normal and jammed).
5.  Display a **confusion matrix** and a **classification report** showing how well it distinguished normal from anomalous data.
6.  Saves the files needed for inference

## Inference 

Prerequisites:
1. `ran-tester-ue`
2. `milcom_jamming_mitigation_demo_modified`
3. `5g core from srsRAN_Project`
4. Setup this repository by creating a virtual environment and installing all required dependencies from requirements.txt

Setup Steps:
1. Make sure that this directory `milcom_jamming_mitigation_demo_modified` is in the same directory as `ran-tester-ue`
2. Move the `gnb_uhd.yaml` and `gnb_uhd_alt.yaml` into `configs/uhd/` subdirectory in `ran-tester-ue/`
3. Run the 5g core
4. cd into ran-tester-ue and run this command: `script -f gnb_session.log`
5. Run the gnodeb with the following command: `sudo gnb -c configs/uhd/gnb_uhd_alt.yaml`
6. Once the connection with gnodeb and ue is established, press t on gnodeb to see trace
7. Open another terminal and run `./unified_script.sh`
8. After iperf3 server is started, run `./ue.sh` after the iperf3 server starts running
9. AI Inference will start running automatically after 10 seconds
10. Once, AI inference is running, start the jammer with following configurations: 
- Sample rate: 23.04e6
- Center Frequency: 1842.5 MHz
- Bandwidth: 10 or 20 MHz
(increase or decrease amplitude and power depending upon setup and requirements. For our testing purpose, the amplitude was set to be 0.7 and Tx gain of 45dB)
11. Observe the CQI and RSRP changing once the jamming is started (also sharp decline in SINR value in UE) and the AI model will trigger the reconnection process

Please verify that the path (we're using relative path and assuming `ran-tester-ue` and `milcom_jamming_mitigation_demo_modified` are in the same subdirectory).

